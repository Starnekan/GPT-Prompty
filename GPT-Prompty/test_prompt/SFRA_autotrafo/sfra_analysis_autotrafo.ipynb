	
cells	
0	
cell_type	"markdown"
id	"6bf6031c"
metadata	{}
source	
0	"# SFRA Analyzer Notebook\n"
1	"\n"
2	"This notebook provides the `SFRAAnalyzer` class for loading, validating, calibrating thresholds, detecting anomalies, and generating prompts based on SFRA measurement data of autotransformers."
1	
cell_type	"code"
execution_count	null
id	"4122d28e"
metadata	{}
outputs	[]
source	
0	"import sys\n"
1	"import logging\n"
2	"from pathlib import Path\n"
3	"from typing import List, Dict, Tuple\n"
4	"\n"
5	"import pandas as pd\n"
6	"\n"
7	"# Konfiguracja logowania\n"
8	"logging.basicConfig(\n"
9	"    level=logging.INFO,\n"
10	'    format="%(asctime)s - %(levelname)s - %(message)s"\n'
11	")\n"
12	"logger = logging.getLogger(__name__)\n"
2	
cell_type	"code"
execution_count	null
id	"fa34b388"
metadata	{}
outputs	[]
source	
0	"class SFRAAnalyzer:\n"
1	'    """\n'
2	"    Klasa do wczytywania, walidacji i analizy danych SFRA autotransformatora,\n"
3	"    z automatycznÄ… korekcjÄ… progÃ³w detekcji anomalii.\n"
4	'    """\n'
5	"    def __init__(\n"
6	"        self,\n"
7	"        file_path: str,\n"
8	'        sep: str = ",",\n'
9	'        encoding: str = "utf-8",\n'
10	"        required_columns: List[str] = None,\n"
11	"        target_anomaly_rate: float = 0.05,\n"
12	"        sigma_step: float = 0.5,\n"
13	"        tol: float = 0.01,\n"
14	"        max_iter: int = 10\n"
15	"    ) -> None:\n"
16	"        self.file_path = Path(file_path)\n"
17	"        self.sep = sep\n"
18	"        self.encoding = encoding\n"
19	"        self.required_columns = required_columns or [\n"
20	'            "Ã¸A RATIO", "Ã¸A RATIO ERROR", "Ã¸A PHASE DEV", "Ã¸A RMS CURRENT",\n'
21	'            "Ã¸B RATIO", "Ã¸B RATIO ERROR", "Ã¸B PHASE DEV", "Ã¸B RMS CURRENT",\n'
22	'            "Ã¸C RATIO", "Ã¸C RATIO ERROR", "Ã¸C PHASE DEV", "Ã¸C RMS CURRENT",\n'
23	"        ]\n"
24	"        # parametry pÄ™tli korekcyjnej\n"
25	"        self.target_anomaly_rate = target_anomaly_rate\n"
26	"        self.sigma_step = sigma_step\n"
27	"        self.tol = tol\n"
28	"        self.max_iter = max_iter\n"
29	"        # do przechowywania wynikÃ³w kalibracji\n"
30	"        self.sigma_multiplier = 2.0\n"
31	"        self.thresholds: Dict[str, float] = {}\n"
32	"\n"
33	"    def load_data(self) -> pd.DataFrame:\n"
34	"        if not self.file_path.exists():\n"
35	'            raise FileNotFoundError(f"Plik nie istnieje: {self.file_path}")\n'
36	"        df = pd.read_csv(self.file_path, sep=self.sep, encoding=self.encoding)\n"
37	"        df.columns = df.columns.str.strip()\n"
38	'        logger.info(f"Wczytano {len(df)} wierszy z pliku {self.file_path}")\n'
39	"        return df\n"
40	"\n"
41	"    def validate_columns(self, df: pd.DataFrame) -> None:\n"
42	"        missing = [col for col in self.required_columns if col not in df.columns]\n"
43	"        if missing:\n"
44	'            raise ValueError(f"BrakujÄ…ce kolumny: {missing}. DostÄ™pne: {df.columns.tolist()}")\n'
45	"\n"
46	"    def _compute_thresholds(self, df: pd.DataFrame) -> None:\n"
47	'        error_cols = [c for c in self.required_columns if c.endswith("ERROR")]\n'
48	'        stats = df[error_cols].agg(["mean", "std"])\n'
49	"        self.thresholds = {\n"
50	'            col: stats.at["mean", col] + self.sigma_multiplier * stats.at["std", col]\n'
51	"            for col in error_cols\n"
52	"        }\n"
53	"\n"
54	"    def detect_anomalies(self, df: pd.DataFrame) -> pd.DataFrame:\n"
55	"        masks = [(df[col] > thr) for col, thr in self.thresholds.items()]\n"
56	"        any_anomaly = pd.concat(masks, axis=1).any(axis=1)\n"
57	"        return df[any_anomaly]\n"
58	"\n"
59	"    def calibrate_thresholds(self, df: pd.DataFrame) -> Tuple[Dict[str, float], pd.DataFrame]:\n"
60	"        for i in range(self.max_iter):\n"
61	"            self._compute_thresholds(df)\n"
62	"            anomalies = self.detect_anomalies(df)\n"
63	"            rate = len(anomalies) / len(df)\n"
64	'            logger.info(f"Iter {i+1}: Ïƒ={self.sigma_multiplier:.2f}, rate={rate:.2%}")\n'
65	"            if abs(rate - self.target_anomaly_rate) <= self.tol:\n"
66	"                break\n"
67	"            if rate > self.target_anomaly_rate:\n"
68	"                self.sigma_multiplier += self.sigma_step\n"
69	"            else:\n"
70	"                self.sigma_multiplier = max(self.sigma_step, self.sigma_multiplier - self.sigma_step)\n"
71	"        self._compute_thresholds(df)\n"
72	"        anomalies = self.detect_anomalies(df)\n"
73	"        return self.thresholds, anomalies\n"
74	"\n"
75	"    def generate_prompt(self, sample: pd.Series) -> str:\n"
76	'        def val(key: str, suffix: str = "") -> str:\n'
77	`            return f"{sample.get(key, 'N/A')}{suffix}"\n`
78	"\n"
79	"        return (\n"
80	'            "Dane z pomiaru SFRA autotransformatora AT-2 (Å»ukowice, 220/110kV):\\n"\n'
81	'            f"- Ã¸A:\\n"\n'
82	`            f"  - RATIO: {val('Ã¸A RATIO')}\\n"\n`
83	`            f"  - ERROR: {val('Ã¸A RATIO ERROR', '%')}\\n"\n`
84	`            f"  - PHASE DEV: {val('Ã¸A PHASE DEV', 'Â°')}\\n"\n`
85	`            f"  - RMS CURRENT: {val('Ã¸A RMS CURRENT', ' A')}\\n"\n`
86	'            "..."\n'
87	"        )\n"
88	"\n"
89	"    def analyze(self) -> None:\n"
90	"        df = self.load_data()\n"
91	"        self.validate_columns(df)\n"
92	"        thresholds, anomalies = self.calibrate_thresholds(df)\n"
93	'        logger.info("Final thresholds:")\n'
94	"        for col, thr in thresholds.items():\n"
95	'            logger.info(f"  {col}: {thr:.2f}%")\n'
96	'        logger.info(f"Anomalies found: {len(anomalies)}")\n'
97	"        if not anomalies.empty:\n"
98	"            prompt = self.generate_prompt(anomalies.iloc[0])\n"
99	'            print("\\n=== PROMPT DLA PIERWSZEJ ANOMALII ===\\n")\n'
100	"            print(prompt)\n"
101	"        else:\n"
102	'            print("ðŸš€ Nie wykryto anomalii")\n'
3	
cell_type	"code"
execution_count	null
id	"89f972e2"
metadata	{}
outputs	[]
source	
0	"# PrzykÅ‚adowe uÅ¼ycie:\n"
1	'if __name__ == "__main__":\n'
2	'    file_path = "TTRU3_EXP_Export_2025-02-20T10_43_02.csv"\n'
3	"    analyzer = SFRAAnalyzer(file_path)\n"
4	"    analyzer.analyze()\n"
metadata	{}
nbformat	4
nbformat_minor	5
