import sys
import logging
from pathlib import Path
from typing import List, Dict, Tuple

import pandas as pd

# Konfiguracja logowania
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(levelname)s - %(message)s"
)
logger = logging.getLogger(__name__)


class SFRAAnalyzer:
    """
    Klasa do wczytywania, walidacji i analizy danych SFRA autotransformatora,
    z automatycznÄ… korekcjÄ… progÃ³w detekcji anomalii.
    """

    def __init__(
        self,
        file_path: str,
        sep: str = ",",
        encoding: str = "utf-8",
        required_columns: List[str] = None,
        target_anomaly_rate: float = 0.05,
        sigma_step: float = 0.5,
        tol: float = 0.01,
        max_iter: int = 10
    ) -> None:
        self.file_path = Path(file_path)
        self.sep = sep
        self.encoding = encoding
        self.required_columns = required_columns or [
            "Ã¸A RATIO", "Ã¸A RATIO ERROR", "Ã¸A PHASE DEV", "Ã¸A RMS CURRENT",
            "Ã¸B RATIO", "Ã¸B RATIO ERROR", "Ã¸B PHASE DEV", "Ã¸B RMS CURRENT",
            "Ã¸C RATIO", "Ã¸C RATIO ERROR", "Ã¸C PHASE DEV", "Ã¸C RMS CURRENT",
        ]
        # parametry pÄ™tli korekcyjnej
        self.target_anomaly_rate = target_anomaly_rate
        self.sigma_step = sigma_step
        self.tol = tol
        self.max_iter = max_iter
        # do przechowywania wynikÃ³w kalibracji
        self.sigma_multiplier = 2.0
        self.thresholds: Dict[str, float] = {}

    def load_data(self) -> pd.DataFrame:
        if not self.file_path.exists():
            raise FileNotFoundError(f"Plik nie istnieje: {self.file_path}")
        try:
            df = pd.read_csv(self.file_path, sep=self.sep, encoding=self.encoding)
        except pd.errors.EmptyDataError:
            raise ValueError("Plik CSV jest pusty lub ma nieprawidÅ‚owy format")
        except pd.errors.ParserError as e:
            raise ValueError(f"BÅ‚Ä…d parsowania CSV: {e}")

        if df.empty:
            raise ValueError("Wczytany DataFrame jest pusty")

        df.columns = df.columns.str.strip()
        logger.info(f"Wczytano {len(df)} wierszy z pliku {self.file_path}")
        logger.debug(f"Kolumny: {df.columns.tolist()}")
        return df

    def validate_columns(self, df: pd.DataFrame) -> None:
        missing = [col for col in self.required_columns if col not in df.columns]
        if missing:
            raise ValueError(
                f"BrakujÄ…ce kolumny: {missing}. "
                f"DostÄ™pne kolumny: {df.columns.tolist()}"
            )

    def _compute_thresholds(self, df: pd.DataFrame) -> None:
        """
        Na podstawie aktualnego sigma_multiplier liczy progi dla kolumn ERROR.
        """
        error_cols = [c for c in self.required_columns if c.endswith("ERROR")]
        stats = df[error_cols].agg(["mean", "std"])
        self.thresholds = {
            col: stats.at["mean", col] + self.sigma_multiplier * stats.at["std", col]
            for col in error_cols
        }
        logger.debug(f"Progi (Ïƒ={self.sigma_multiplier}): {self.thresholds}")

    def detect_anomalies(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        Zwraca podzbiÃ³r wierszy, w ktÃ³rych ktÃ³raÅ› kolumna ERROR przekracza prÃ³g.
        """
        masks = []
        for col, thr in self.thresholds.items():
            masks.append(df[col] > thr)
        any_anomaly = pd.concat(masks, axis=1).any(axis=1)
        return df[any_anomaly]

    def calibrate_thresholds(self, df: pd.DataFrame) -> Tuple[Dict[str, float], pd.DataFrame]:
        """
        PÄ™tla korekcyjna:
        - liczy progi na podstawie Å›redniej + sigma_multiplier*std
        - sprawdza odsetek anomalii
        - dostosowuje sigma_multiplier aÅ¼ odsetek anomalii ~ target_anomaly_rate
        """
        for i in range(self.max_iter):
            self._compute_thresholds(df)
            anomalies = self.detect_anomalies(df)
            rate = len(anomalies) / len(df)
            logger.info(
                f"Iteracja {i+1}: Ïƒ={self.sigma_multiplier:.2f}, "
                f"anomalii={len(anomalies)}/{len(df)} ({rate:.2%})"
            )
            if abs(rate - self.target_anomaly_rate) <= self.tol:
                break
            # jeÅ›li jest za duÅ¼o anomalii â†’ bardziej liberalny prÃ³g (wiÄ™ksze sigma)
            if rate > self.target_anomaly_rate:
                self.sigma_multiplier += self.sigma_step
            else:
                # zbyt maÅ‚o â†’ zaostrzamy detekcjÄ™
                self.sigma_multiplier = max(self.sigma_step, self.sigma_multiplier - self.sigma_step)
        else:
            logger.warning("OsiÄ…gniÄ™to maksymalnÄ… liczbÄ™ iteracji kalibracji")

        # finalne progi i zestaw wierszy-anomalii
        self._compute_thresholds(df)
        anomalies = self.detect_anomalies(df)
        return self.thresholds, anomalies

    def generate_prompt(self, sample: pd.Series) -> str:
        def val(key: str, suffix: str = "") -> str:
            return f"{sample.get(key, 'N/A')}{suffix}"

        return (
            "Dane z pomiaru SFRA autotransformatora AT-2 (Å»ukowice, 220/110kV):\n"
            f"- Ã¸A:\n"
            f"  - RATIO: {val('Ã¸A RATIO')}\n"
            f"  - ERROR: {val('Ã¸A RATIO ERROR', '%')}\n"
            f"  - PHASE DEV: {val('Ã¸A PHASE DEV', 'Â°')}\n"
            f"  - RMS CURRENT: {val('Ã¸A RMS CURRENT', ' A')}\n"
            f"- Ã¸B:\n"
            f"  - RATIO: {val('Ã¸B RATIO')}\n"
            f"  - ERROR: {val('Ã¸B RATIO ERROR', '%')}\n"
            f"  - PHASE DEV: {val('Ã¸B PHASE DEV', 'Â°')}\n"
            f"  - RMS CURRENT: {val('Ã¸B RMS CURRENT', ' A')}\n"
            f"- Ã¸C:\n"
            f"  - RATIO: {val('Ã¸C RATIO')}\n"
            f"  - ERROR: {val('Ã¸C RATIO ERROR', '%')}\n"
            f"  - PHASE DEV: {val('Ã¸C PHASE DEV', 'Â°')}\n"
            f"  - RMS CURRENT: {val('Ã¸C RMS CURRENT', ' A')}\n\n"
            "Pomiar inspekcyjny. OceÅ„ poprawnoÅ›Ä‡, wskaÅ¼ anomalie i zaproponuj dalsze dziaÅ‚ania serwisowe."
        )

    def analyze(self) -> None:
        df = self.load_data()
        self.validate_columns(df)

        # 1) kalibracja progÃ³w
        thresholds, anomalies = self.calibrate_thresholds(df)

        # 2) podsumowanie
        logger.info("Ostateczne progi dla kolumn ERROR:")
        for col, thr in thresholds.items():
            logger.info(f"  {col}: {thr:.2f}%")

        logger.info(f"Znaleziono {len(anomalies)} wierszy-anomalii.")
        if not anomalies.empty:
            # wypisz kilka pierwszych przykÅ‚adÃ³w
            logger.info("PrzykÅ‚ady anomalii (pierwsze 5 wierszy):")
            logger.info(anomalies[self.required_columns].head().to_string())

        # 3) wygeneruj prompt dla pierwszej anomalii, jeÅ›li istnieje
        if not anomalies.empty:
            prompt = self.generate_prompt(anomalies.iloc[0])
            print("\n=== PROMPT DLA PIERWSZEJ ANOMALII ===\n")
            print(prompt)
        else:
            print("ðŸš€ Nie wykryto anomalii â€“ wszystkie pomiary mieszczÄ… siÄ™ w skalibrowanych progach.")


def main() -> None:
    file_path = sys.argv[1] if len(sys.argv) > 1 else "TTRU3_EXP_Export_2025-02-20T10_43_02.csv"
    analyzer = SFRAAnalyzer(file_path)

    try:
        analyzer.analyze()
    except Exception as e:
        logger.error(e)
        sys.exit(1)


if __name__ == "__main__":
    main()
