import sys
import logging
from pathlib import Path
from typing import List, Dict, Tuple

import pandas as pd

# Konfiguracja logowania
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(levelname)s - %(message)s"
)
logger = logging.getLogger(__name__)


class SFRAAnalyzer:
    """
    Klasa do wczytywania, walidacji i analizy danych SFRA autotransformatora,
    z automatycznÄ… korekcjÄ… progÃ³w detekcji anomalii.
    """
    def __init__(
        self,
        file_path: str,
        sep: str = ",",
        encoding: str = "utf-8",
        required_columns: List[str] = None,
        target_anomaly_rate: float = 0.05,
        sigma_step: float = 0.5,
        tol: float = 0.01,
        max_iter: int = 10,
        force_prompt_on_no_anomalies: bool = True
    ) -> None:
        self.file_path = Path(file_path)
        self.sep = sep
        self.encoding = encoding
        self.required_columns = required_columns or [
            "Ã¸A RATIO", "Ã¸A RATIO ERROR", "Ã¸A PHASE DEV", "Ã¸A RMS CURRENT",
            "Ã¸B RATIO", "Ã¸B RATIO ERROR", "Ã¸B PHASE DEV", "Ã¸B RMS CURRENT",
            "Ã¸C RATIO", "Ã¸C RATIO ERROR", "Ã¸C PHASE DEV", "Ã¸C RMS CURRENT",
        ]
        self.target_anomaly_rate = target_anomaly_rate
        self.sigma_step = sigma_step
        self.tol = tol
        self.max_iter = max_iter
        self.sigma_multiplier = 2.0
        self.thresholds: Dict[str, float] = {}
        self.force_prompt_on_no_anomalies = force_prompt_on_no_anomalies

    def load_data(self) -> pd.DataFrame:
        if not self.file_path.exists():
            raise FileNotFoundError(f"Plik nie istnieje: {self.file_path}")
        df = pd.read_csv(self.file_path, sep=self.sep, encoding=self.encoding)
        df.columns = df.columns.str.strip()
        logger.info(f"Wczytano {len(df)} wierszy z pliku {self.file_path.name}")
        return df

    def validate_columns(self, df: pd.DataFrame) -> None:
        missing = [col for col in self.required_columns if col not in df.columns]
        if missing:
            raise ValueError(f"BrakujÄ…ce kolumny: {missing}. DostÄ™pne: {df.columns.tolist()}")

    def _compute_thresholds(self, df: pd.DataFrame) -> None:
        error_cols = [c for c in self.required_columns if c.endswith("ERROR")]
        stats = df[error_cols].agg(["mean", "std"])
        self.thresholds = {
            col: stats.at["mean", col] + self.sigma_multiplier * stats.at["std", col]
            for col in error_cols
        }

    def detect_anomalies(self, df: pd.DataFrame) -> pd.DataFrame:
        masks = [(df[col] > thr) for col, thr in self.thresholds.items()]
        any_anomaly = pd.concat(masks, axis=1).any(axis=1)
        return df[any_anomaly]

    def calibrate_thresholds(self, df: pd.DataFrame) -> Tuple[Dict[str, float], pd.DataFrame]:
        for i in range(self.max_iter):
            self._compute_thresholds(df)
            anomalies = self.detect_anomalies(df)
            rate = len(anomalies) / len(df)
            logger.info(f"{self.file_path.name} â€” Iter {i+1}: Ïƒ={self.sigma_multiplier:.2f}, rate={rate:.2%}")
            if abs(rate - self.target_anomaly_rate) <= self.tol:
                break
            if rate > self.target_anomaly_rate:
                self.sigma_multiplier += self.sigma_step
            else:
                self.sigma_multiplier = max(self.sigma_step, self.sigma_multiplier - self.sigma_step)
        self._compute_thresholds(df)
        anomalies = self.detect_anomalies(df)
        return self.thresholds, anomalies

    def generate_prompt(self, sample: pd.Series) -> str:
        def val(key: str, suffix: str = "") -> str:
            return f"{sample.get(key, 'N/A')}{suffix}"

        return (
            f"Dane z pomiaru SFRA autotransformatora ({self.file_path.name}):\n"
            f"- Ã¸A:\n"
            f"  - RATIO: {val('Ã¸A RATIO')}\n"
            f"  - ERROR: {val('Ã¸A RATIO ERROR', '%')}\n"
            f"  - PHASE DEV: {val('Ã¸A PHASE DEV', 'Â°')}\n"
            f"  - RMS CURRENT: {val('Ã¸A RMS CURRENT', ' A')}\n"
            f"- Ã¸B:\n"
            f"  - RATIO: {val('Ã¸B RATIO')}\n"
            f"  - ERROR: {val('Ã¸B RATIO ERROR', '%')}\n"
            f"  - PHASE DEV: {val('Ã¸B PHASE DEV', 'Â°')}\n"
            f"  - RMS CURRENT: {val('Ã¸B RMS CURRENT', ' A')}\n"
            f"- Ã¸C:\n"
            f"  - RATIO: {val('Ã¸C RATIO')}\n"
            f"  - ERROR: {val('Ã¸C RATIO ERROR', '%')}\n"
            f"  - PHASE DEV: {val('Ã¸C PHASE DEV', 'Â°')}\n"
            f"  - RMS CURRENT: {val('Ã¸C RMS CURRENT', ' A')}\n"
        )

    def analyze(self) -> None:
        try:
            df = self.load_data()
            self.validate_columns(df)
            thresholds, anomalies = self.calibrate_thresholds(df)
            logger.info(f"{self.file_path.name} â€” Final thresholds: {self.thresholds}")
            if not anomalies.empty:
                prompt = self.generate_prompt(anomalies.iloc[0])
                print(f"\n=== PROMPT DLA PIERWSZEJ ANOMALII ({self.file_path.name}) ===\n")
                print(prompt)
            elif self.force_prompt_on_no_anomalies:
                prompt = self.generate_prompt(df.iloc[0])
                print(f"\n=== PROMPT (brak anomalii â€“ pierwszy rekord) dla {self.file_path.name} ===\n")
                print(prompt)
            else:
                print(f"ðŸš€ {self.file_path.name}: Nie wykryto anomalii")
        except Exception as e:
            logger.error(f"BÅ‚Ä…d w analizie {self.file_path.name}: {e}")


if __name__ == "__main__":
    # katalog, w ktÃ³rym znajdujÄ… siÄ™ wszystkie pliki CSV do analizy
    data_dir = Path(".")  # Use current directory instead of __file__.parent
    csv_files = list(data_dir.glob("*.csv"))

    if not csv_files:
        logger.error(f"Nie znaleziono Å¼adnych plikÃ³w .csv w katalogu {data_dir}")
        sys.exit(1)

    for csv in csv_files:
        analyzer = SFRAAnalyzer(
            file_path=str(csv),
            force_prompt_on_no_anomalies=True
        )
        analyzer.analyze()
